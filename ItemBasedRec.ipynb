{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ItemBasedRec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfP1Il101vZ2a09y+P54gy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TB1G2EkiR73"
      },
      "outputs": [],
      "source": [
        "######################################\n",
        "# Item-Based Collaborative Filtering (Item-Item Filtering) #\n",
        "\n",
        "\n",
        "######################################\n",
        "# Preparation of Dataset\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 20)\n",
        "\n",
        "#movie.csv is 27278x3\n",
        "movie = pd.read_csv('/content/movie.csv')\n",
        "#rating.csv is 14191605x4\n",
        "rating = pd.read_csv('/content/rating.csv')\n",
        "\n",
        "#we need to merge them by movieId to match ratings and movies\n",
        "#df will be our merged main database\n",
        "df = movie.merge(rating, how=\"left\", on=\"movieId\")\n",
        "\n",
        "\n",
        "######################################\n",
        "# Creating movie_df\n",
        "\n",
        "#Firstly, let's examine our merged database\n",
        "df.head()\n",
        "df.shape\n",
        "\n",
        "#look for unique titles to learn how many movies we have in df\n",
        "df[\"title\"].nunique()\n",
        "\n",
        "#here are the top 5 movies that rated by users\n",
        "df[\"title\"].value_counts().head()\n",
        "\n",
        "#we define rating_counts as we know the total number of rates to movies\n",
        "rating_count = pd.DataFrame(df[\"title\"].value_counts())\n",
        "\n",
        "#we drop least rated movies, here we say at least 1000 ratings\n",
        "#name the selected movies as common_movies\n",
        "rare_movies = rating_count[rating_count[\"title\"] <= 1000].index\n",
        "common_movies = df[~df[\"title\"].isin(rare_movies)]\n",
        "common_movies.shape\n",
        "common_movies[\"title\"].nunique() #we have 2544 movies left\n",
        "\n",
        "#we will have movie names as columns and userID as rows\n",
        "movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n",
        "\n",
        "#let's see if it is like what we want\n",
        "movie_df.shape #(97985, 2544)\n",
        "movie_df.columns # movie names\n",
        "movie_df.head(10)\n",
        "\n",
        "\n",
        "######################################\n",
        "# Item-Based Movie Suggestions\n",
        "\n",
        "#Now we can calculated a suggestion with calculating the correlation\n",
        "#for example let's pick Matrix\n",
        "movie_name = \"Matrix, The (1999)\"\n",
        "movie_name = movie_df[movie_name]\n",
        "movie_df.corrwith(movie_name).sort_values(ascending=False).head(10)\n",
        "\n",
        "\n",
        "movie_name = \"Ocean's Twelve (2004)\"\n",
        "movie_name = movie_df[movie_name]\n",
        "movie_df.corrwith(movie_name).sort_values(ascending=False).head(10)\n",
        "\n",
        "\n",
        "#Now we can pick a randomly movie\n",
        "movie_name = pd.Series(movie_df.columns).sample(1).values[0]\n",
        "movie_name = movie_df[movie_name]\n",
        "movie_df.corrwith(movie_name).sort_values(ascending=False).head(10)\n",
        "\n",
        "\n",
        "\n",
        "######################################\n",
        "# Sum up: Functions\n",
        "# Let's sum all up and write with functions for different variables\n",
        "######################################\n",
        "import pandas as pd \n",
        "\n",
        "def create_movie_df(nr_drop_movie):\n",
        "  #change these paths with your own path of database\n",
        "    movie = pd.read_csv('/content/movie.csv')\n",
        "    rating = pd.read_csv('/content/rating.csv')\n",
        "    #merge datasets\n",
        "    df = movie.merge(rating, how=\"left\", on=\"movieId\")\n",
        "    rating_count = pd.DataFrame(df[\"title\"].value_counts())\n",
        "  #nr_drop_movies= number of dropped movies from list\n",
        "    rare_movies = rating_count[rating_count[\"title\"] <= nr_drop_movie].index\n",
        "    common_movies = df[~df[\"title\"].isin(rare_movies)]\n",
        "    movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n",
        "    return movie_df\n",
        "\n",
        "def item_based_recommender(movie_name, movie_df):\n",
        "    movie_name = user_movie_df[movie_name]\n",
        "    return user_movie_df.corrwith(movie_name).sort_values(ascending=False).head(10)\n",
        "\n",
        "\n",
        "movie_df = create_movie_df(nr_drop_movie=1000)\n",
        "\n",
        "#example for Sherlock Holmes\n",
        "item_based_recommender(\"Sherlock Holmes (2009)\", movie_df)\n",
        "\n",
        "#for randomly picked movie\n",
        "movie_name = pd.Series(movie_df.columns).sample(1).values[0]\n",
        "item_based_recommender(movie_name, movie_df)\n",
        "\n",
        "\n"
      ]
    }
  ]
}